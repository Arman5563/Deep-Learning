{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ec1aaa",
   "metadata": {},
   "source": [
    "## Student Identity\n",
    "Name: Arman Lotfalikhani <br>\n",
    "Student Number: 99109166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009fadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5733d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "train_set = MNIST(root='.', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_set = MNIST(root='.', train=False, download=True, transform=transforms.ToTensor())\n",
    "num_classes = len(MNIST.classes)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f46071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, 50000, shuffle=True)\n",
    "test_loader = DataLoader(test_set, 10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bceff2f",
   "metadata": {},
   "source": [
    "### Mask_Creator\n",
    "In the following cell, in addition to the previously-defined FFLayer and FFNet, a new class named Mask_Creator is defined and used. <br>\n",
    "Initialization: In the paper, it was proposed that after generating a random mask, we use a filter $[1/4, 1/2, 1/4]$ and convolve it horizontally and verticaly multiple times, and then put a 0.5 threshold on the output. So we define W and WT (W-transpose), and added new dimensions to it (its shape is $[1,1,1,3]$)to avoid errors. <br>\n",
    "The reason for its inheritance from nn.Module is only to hint that it is intended for PyTorch tensors, and hence a forward method was created. But the main functionality in through mask().\n",
    "\n",
    "### Masking the dataset\n",
    "In the paper, it was advised that we combine two valid images by coefficients of mask and 1-mask. This is implemented inside the train function. For each minibatch, the data are shuffled randomly by using a torch.randperm function and are then combined with the original data with the mentioned coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fff25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "class FFLayer(nn.Module):\n",
    "    def __init__(self, epsilon, in_dim, out_dim, threshold, lr, device='cpu',dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Linear(in_features=in_dim, out_features=out_dim, bias=True, device=device, dtype=dtype),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.threshold=threshold\n",
    "        self.device=device\n",
    "        self.dtype=dtype\n",
    "        self.optimizer=torch.optim.Adam(self.parameters(),lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_normalized = x / (x.norm(2, 1, keepdim=True) + 1e-5)\n",
    "        return self.layer(x_normalized)\n",
    "    \n",
    "    def optimizer_step(self, x_pos,x_neg):\n",
    "        pos_f=self.forward(x_pos)\n",
    "        neg_f=self.forward(x_neg)\n",
    "        goodness_pos=torch.square(pos_f).mean(1)\n",
    "        goodness_neg=torch.square(neg_f).mean(1)\n",
    "\n",
    "        loss=torch.log(1+ torch.cat([torch.exp(-goodness_pos+self.threshold),\n",
    "                                    torch.exp(goodness_neg-self.threshold)] ) ).mean()        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return loss\n",
    "    \n",
    "class Mask_Creator(nn.Module):\n",
    "    def __init__(self, n, device='cpu',dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.W=torch.tensor([[1/4, 1/2, 1/4]]).to(device).type(dtype)\n",
    "        self.W=self.W[None, None, :]\n",
    "        self.WT=torch.transpose(self.W,2,3)\n",
    "        self.n=n\n",
    "        self.device=device\n",
    "        self.dtype=dtype\n",
    "    \n",
    "    def mask(self, input_tensor):\n",
    "        rand_vs=torch.rand(input_tensor.size()).to(self.device).type(self.dtype)\n",
    "        out =self.forward(rand_vs)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x): #Implemented beacuse of inheritance from nn.Module\n",
    "        y=x.clone()\n",
    "        for i in range(self.n):\n",
    "            y=F.conv2d(y, self.W, bias=None, stride=1, padding='same', dilation=1, groups=1)\n",
    "            y=F.conv2d(y, self.WT, bias=None, stride=1, padding='same', dilation=1, groups=1)\n",
    "        y=torch.sign(F.relu(y-0.5)) #A trick for heaviside function without casting do device and type issues\n",
    "        return y\n",
    "\n",
    "\n",
    "class FFNet():\n",
    "    def __init__(self,epsilon, dims, n_mask, threshold_list, lr, device='cpu',dtype=torch.float32):\n",
    "        '''Note: threshold_list must have size L and dims must have the size L+1. L: number of layers'''\n",
    "        super().__init__()\n",
    "        self.layers=[]\n",
    "        self.device=device\n",
    "        self.mask_c=Mask_Creator(n_mask, device=device, dtype=dtype)\n",
    "        for i in range(len(dims)-1):\n",
    "            self.layers.append(FFLayer(epsilon, in_dim=dims[i], out_dim=dims[i+1], device=device, \n",
    "                                       dtype=dtype, threshold=threshold_list[i], lr=lr))\n",
    "        print(self.layers)\n",
    "    def train(self, num_epochs, train_dataloader):\n",
    "        data=None\n",
    "        for i,train in enumerate(train_dataloader,0):\n",
    "            data=train\n",
    "        L=len(self.layers)\n",
    "        for l in range(L):\n",
    "            print('Training layer: ',l+1)\n",
    "            for epoch in range(num_epochs):\n",
    "                running_loss= 0.0\n",
    "                \n",
    "                images=data[0].to(self.device)\n",
    "                \n",
    "                indices=torch.randperm(images.size(0))\n",
    "                false_images=images[indices]\n",
    "                mask=self.mask_c.mask(images)\n",
    "                \n",
    "                neg_images=torch.mul(mask,images)+torch.mul(1-mask, false_images)\n",
    "\n",
    "                images=torch.flatten(images,start_dim=1)/torch.max(images) #Scale between zero and one\n",
    "                neg_images=torch.flatten(neg_images,start_dim=1)/torch.max(images) #Scale between zero and one\n",
    "                \n",
    "                pos_data=self.forward_for_layer( l,images )\n",
    "                neg_data=self.forward_for_layer( l, neg_images)\n",
    "\n",
    "                running_loss+= self.layers[l].optimizer_step(pos_data,neg_data)\n",
    "                running_loss_mean=running_loss\n",
    "                if (epoch+1)%20==0:\n",
    "                    print(\"Epoch: %i Running loss: %f\"%(epoch+1, running_loss_mean))\n",
    "                    \n",
    "    def forward_for_layer(self,i,x): #Forwards the data for layer i in the training process\n",
    "        y=x.clone()\n",
    "        with torch.no_grad():\n",
    "            for j in range(i):\n",
    "                y=self.layers[j].forward(y)\n",
    "        return y.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8076d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269a2ed9a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mask=Mask_Creator(5, device=device, dtype=torch.float32)\n",
    "x_train, y_train = next(iter(train_loader))\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "masked=mask.mask(x_train)\n",
    "sample=1-masked[100][0]\n",
    "plt.imshow(sample.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9968a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FFLayer(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "), FFLayer(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")]\n",
      "Training layer:  1\n",
      "Epoch: 20 Running loss: 0.870259\n",
      "Epoch: 40 Running loss: 0.728929\n",
      "Epoch: 60 Running loss: 0.725497\n",
      "Epoch: 80 Running loss: 0.721813\n",
      "Epoch: 100 Running loss: 0.722260\n",
      "Epoch: 120 Running loss: 0.719738\n",
      "Epoch: 140 Running loss: 0.715848\n",
      "Epoch: 160 Running loss: 0.711935\n",
      "Epoch: 180 Running loss: 0.706214\n",
      "Epoch: 200 Running loss: 0.698745\n",
      "Epoch: 220 Running loss: 0.688208\n",
      "Epoch: 240 Running loss: 0.676141\n",
      "Epoch: 260 Running loss: 0.668215\n",
      "Epoch: 280 Running loss: 0.659497\n",
      "Epoch: 300 Running loss: 0.648927\n",
      "Epoch: 320 Running loss: 0.638171\n",
      "Epoch: 340 Running loss: 0.626269\n",
      "Epoch: 360 Running loss: 0.610086\n",
      "Epoch: 380 Running loss: 0.596550\n",
      "Epoch: 400 Running loss: 0.583675\n",
      "Epoch: 420 Running loss: 0.572488\n",
      "Epoch: 440 Running loss: 0.560689\n",
      "Epoch: 460 Running loss: 0.552668\n",
      "Epoch: 480 Running loss: 0.547035\n",
      "Epoch: 500 Running loss: 0.538901\n",
      "Epoch: 520 Running loss: 0.528954\n",
      "Epoch: 540 Running loss: 0.527510\n",
      "Epoch: 560 Running loss: 0.517891\n",
      "Epoch: 580 Running loss: 0.513218\n",
      "Epoch: 600 Running loss: 0.503844\n",
      "Training layer:  2\n",
      "Epoch: 20 Running loss: 1.131528\n",
      "Epoch: 40 Running loss: 0.850329\n",
      "Epoch: 60 Running loss: 0.797334\n",
      "Epoch: 80 Running loss: 0.781532\n",
      "Epoch: 100 Running loss: 0.770232\n",
      "Epoch: 120 Running loss: 0.761740\n",
      "Epoch: 140 Running loss: 0.756493\n",
      "Epoch: 160 Running loss: 0.747582\n",
      "Epoch: 180 Running loss: 0.743090\n",
      "Epoch: 200 Running loss: 0.735541\n",
      "Epoch: 220 Running loss: 0.728691\n",
      "Epoch: 240 Running loss: 0.721867\n",
      "Epoch: 260 Running loss: 0.717133\n",
      "Epoch: 280 Running loss: 0.709790\n",
      "Epoch: 300 Running loss: 0.704437\n",
      "Epoch: 320 Running loss: 0.697039\n",
      "Epoch: 340 Running loss: 0.690891\n",
      "Epoch: 360 Running loss: 0.687449\n",
      "Epoch: 380 Running loss: 0.680717\n",
      "Epoch: 400 Running loss: 0.675448\n",
      "Epoch: 420 Running loss: 0.669748\n",
      "Epoch: 440 Running loss: 0.666024\n",
      "Epoch: 460 Running loss: 0.659661\n",
      "Epoch: 480 Running loss: 0.656444\n",
      "Epoch: 500 Running loss: 0.651680\n",
      "Epoch: 520 Running loss: 0.647735\n",
      "Epoch: 540 Running loss: 0.647631\n",
      "Epoch: 560 Running loss: 0.643027\n",
      "Epoch: 580 Running loss: 0.639010\n",
      "Epoch: 600 Running loss: 0.636812\n"
     ]
    }
   ],
   "source": [
    "net=FFNet(epsilon=1e-2,dims=[784,400,300],n_mask=5, device=device,dtype=torch.float32, threshold_list=[3, 4], lr=0.01)\n",
    "net.train(600, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66cf2c",
   "metadata": {},
   "source": [
    "### Linear classifier <br>\n",
    "For evaluating the unsupervised layers, we need another supervised layer to see if the extracted features were good enough.\n",
    "\n",
    "The structure of the Linear_Classifier class is similar to the previous neural net structures, with a batch normalization layer before the linear layer and with a crossentropy loss. Also, the prediction function is fully vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b88465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_classifier(nn.Module):\n",
    "    def __init__(self, epsilon, in_dim, num_classes, lr, device='cpu',dtype=torch.float32):\n",
    "        super().__init__() \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features=in_dim,eps=epsilon,affine=False, device=device, dtype=dtype),\n",
    "            nn.Linear(in_features=in_dim, out_features=num_classes, bias=True, device=device, dtype=dtype)\n",
    "        ) \n",
    "        self.device=device\n",
    "        self.dtype=dtype\n",
    "        self.optimizer=torch.optim.Adam(self.parameters(),lr)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out= self.layer(X)\n",
    "        return out\n",
    "    \n",
    "    def train(self, X,y,num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss= self.optimizer_step(self.forward(X),y)\n",
    "            if (epoch+1)%5==0:\n",
    "                print(\"Epoch: %i Running loss: %f\"%(epoch+1, running_loss))\n",
    "        return\n",
    "    \n",
    "    def optimizer_step(self, X,y):\n",
    "        loss_f=nn.CrossEntropyLoss()\n",
    "        loss=loss_f(X,y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, X_test, y_test):\n",
    "        with torch.no_grad():\n",
    "            predictions=torch.argmax(self.forward(X_test),1)\n",
    "            correct=torch.sum(torch.eq(predictions,y_test)).item()\n",
    "            total=len(predictions)\n",
    "        return correct,total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a62c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Running loss: 1.134810\n",
      "Epoch: 10 Running loss: 1.124351\n",
      "Epoch: 15 Running loss: 1.056410\n",
      "Epoch: 20 Running loss: 0.968943\n",
      "Epoch: 25 Running loss: 0.898531\n",
      "Epoch: 30 Running loss: 0.875756\n",
      "Epoch: 35 Running loss: 0.859196\n",
      "Epoch: 40 Running loss: 0.836450\n",
      "Epoch: 45 Running loss: 0.823473\n",
      "Epoch: 50 Running loss: 0.812089\n",
      "Epoch: 55 Running loss: 0.801607\n",
      "Epoch: 60 Running loss: 0.793118\n",
      "Epoch: 65 Running loss: 0.784976\n",
      "Epoch: 70 Running loss: 0.777676\n",
      "Epoch: 75 Running loss: 0.770905\n",
      "Epoch: 80 Running loss: 0.764637\n"
     ]
    }
   ],
   "source": [
    "lin=Linear_classifier(epsilon=1e-2, in_dim=300, num_classes=10, lr=0.01, device=device,dtype=torch.float32)\n",
    "images=torch.flatten(x_train,start_dim=1)\n",
    "x_out=net.forward_for_layer(2,images)\n",
    "lin.train(x_out,y_train,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9202d077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  37126 Total:  50000 Error=  0.25748000000000004\n"
     ]
    }
   ],
   "source": [
    "train_images=torch.flatten(x_train,start_dim=1)\n",
    "x_train_out=net.forward_for_layer(2,train_images)\n",
    "train_true,train_tot=lin.predict(x_train_out,y_train)\n",
    "print('True: ', train_true, 'Total: ', train_tot, 'Error= ', 1-train_true/train_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ff7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  7450 Total:  10000 Error=  0.255\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = next(iter(test_loader))\n",
    "x_test, y_test = x_test.cuda(), y_test.cuda()\n",
    "test_images=torch.flatten(x_test,start_dim=1)\n",
    "x_test_out=net.forward_for_layer(2,test_images)\n",
    "test_true,test_tot=lin.predict(x_test_out,y_test)\n",
    "print('True: ', test_true, 'Total: ', test_tot, 'Error= ', 1-test_true/test_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b3624",
   "metadata": {},
   "source": [
    "### Result report: <br>\n",
    "It is clear the model is working properly, as the accuracies are decent and far from the truly-random-10%. In the next cells,\n",
    "we try to change some hyperparameters to get a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d10df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FFLayer(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "), FFLayer(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")]\n",
      "Training layer:  1\n",
      "Epoch: 20 Running loss: 0.866091\n",
      "Epoch: 40 Running loss: 0.730599\n",
      "Epoch: 60 Running loss: 0.726306\n",
      "Epoch: 80 Running loss: 0.721734\n",
      "Epoch: 100 Running loss: 0.722137\n",
      "Epoch: 120 Running loss: 0.722335\n",
      "Epoch: 140 Running loss: 0.716773\n",
      "Epoch: 160 Running loss: 0.714428\n",
      "Epoch: 180 Running loss: 0.711641\n",
      "Epoch: 200 Running loss: 0.702202\n",
      "Epoch: 220 Running loss: 0.693829\n",
      "Epoch: 240 Running loss: 0.682171\n",
      "Epoch: 260 Running loss: 0.669948\n",
      "Epoch: 280 Running loss: 0.659766\n",
      "Epoch: 300 Running loss: 0.648780\n",
      "Epoch: 320 Running loss: 0.635694\n",
      "Epoch: 340 Running loss: 0.627252\n",
      "Epoch: 360 Running loss: 0.609477\n",
      "Epoch: 380 Running loss: 0.597045\n",
      "Epoch: 400 Running loss: 0.581158\n",
      "Epoch: 420 Running loss: 0.569634\n",
      "Epoch: 440 Running loss: 0.560789\n",
      "Epoch: 460 Running loss: 0.552901\n",
      "Epoch: 480 Running loss: 0.548700\n",
      "Epoch: 500 Running loss: 0.541062\n",
      "Epoch: 520 Running loss: 0.539112\n",
      "Epoch: 540 Running loss: 0.529935\n",
      "Epoch: 560 Running loss: 0.519944\n",
      "Epoch: 580 Running loss: 0.516127\n",
      "Epoch: 600 Running loss: 0.509445\n",
      "Training layer:  2\n",
      "Epoch: 20 Running loss: 0.950687\n",
      "Epoch: 40 Running loss: 0.783329\n",
      "Epoch: 60 Running loss: 0.754143\n",
      "Epoch: 80 Running loss: 0.742158\n",
      "Epoch: 100 Running loss: 0.734014\n",
      "Epoch: 120 Running loss: 0.727674\n",
      "Epoch: 140 Running loss: 0.719493\n",
      "Epoch: 160 Running loss: 0.711770\n",
      "Epoch: 180 Running loss: 0.702815\n",
      "Epoch: 200 Running loss: 0.697417\n",
      "Epoch: 220 Running loss: 0.693326\n",
      "Epoch: 240 Running loss: 0.687158\n",
      "Epoch: 260 Running loss: 0.681759\n",
      "Epoch: 280 Running loss: 0.676746\n",
      "Epoch: 300 Running loss: 0.674410\n",
      "Epoch: 320 Running loss: 0.667948\n",
      "Epoch: 340 Running loss: 0.663438\n",
      "Epoch: 360 Running loss: 0.658470\n",
      "Epoch: 380 Running loss: 0.656741\n",
      "Epoch: 400 Running loss: 0.649763\n",
      "Epoch: 420 Running loss: 0.646461\n",
      "Epoch: 440 Running loss: 0.643443\n",
      "Epoch: 460 Running loss: 0.639226\n",
      "Epoch: 480 Running loss: 0.636202\n",
      "Epoch: 500 Running loss: 0.636588\n",
      "Epoch: 520 Running loss: 0.632412\n",
      "Epoch: 540 Running loss: 0.628902\n",
      "Epoch: 560 Running loss: 0.626659\n",
      "Epoch: 580 Running loss: 0.625226\n",
      "Epoch: 600 Running loss: 0.622767\n"
     ]
    }
   ],
   "source": [
    "net2=FFNet(epsilon=1e-2,dims=[784,400,300],n_mask=5, device=device,dtype=torch.float32, threshold_list=[3, 3], lr=0.01)\n",
    "net2.train(600, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c31cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Running loss: 1.391962\n",
      "Epoch: 10 Running loss: 1.325142\n",
      "Epoch: 15 Running loss: 1.137025\n",
      "Epoch: 20 Running loss: 0.972278\n",
      "Epoch: 25 Running loss: 0.920268\n",
      "Epoch: 30 Running loss: 0.857546\n",
      "Epoch: 35 Running loss: 0.830808\n",
      "Epoch: 40 Running loss: 0.789159\n",
      "Epoch: 45 Running loss: 0.772138\n",
      "Epoch: 50 Running loss: 0.752636\n",
      "Epoch: 55 Running loss: 0.742367\n",
      "Epoch: 60 Running loss: 0.729108\n",
      "Epoch: 65 Running loss: 0.720158\n",
      "Epoch: 70 Running loss: 0.711395\n",
      "Epoch: 75 Running loss: 0.704156\n",
      "Epoch: 80 Running loss: 0.697398\n",
      "Epoch: 85 Running loss: 0.691278\n",
      "Epoch: 90 Running loss: 0.685658\n",
      "Epoch: 95 Running loss: 0.680356\n",
      "Epoch: 100 Running loss: 0.675428\n",
      "Epoch: 105 Running loss: 0.670777\n",
      "Epoch: 110 Running loss: 0.666381\n",
      "Epoch: 115 Running loss: 0.662213\n",
      "Epoch: 120 Running loss: 0.658248\n",
      "Epoch: 125 Running loss: 0.654466\n",
      "Epoch: 130 Running loss: 0.650855\n",
      "Epoch: 135 Running loss: 0.647396\n",
      "Epoch: 140 Running loss: 0.644081\n",
      "Epoch: 145 Running loss: 0.640897\n",
      "Epoch: 150 Running loss: 0.637836\n",
      "Epoch: 155 Running loss: 0.634889\n",
      "Epoch: 160 Running loss: 0.632049\n",
      "Epoch: 165 Running loss: 0.629309\n",
      "Epoch: 170 Running loss: 0.626663\n",
      "Epoch: 175 Running loss: 0.624105\n",
      "Epoch: 180 Running loss: 0.621630\n",
      "Epoch: 185 Running loss: 0.619234\n",
      "Epoch: 190 Running loss: 0.616911\n",
      "Epoch: 195 Running loss: 0.614658\n",
      "Epoch: 200 Running loss: 0.612472\n"
     ]
    }
   ],
   "source": [
    "lin2=Linear_classifier(epsilon=1e-2, in_dim=300, num_classes=10, lr=0.02, device=device,dtype=torch.float32)\n",
    "x_out2=net2.forward_for_layer(2,images)\n",
    "lin2.train(x_out2,y_train,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac537729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  39881 Total:  50000 Error=  0.20238\n"
     ]
    }
   ],
   "source": [
    "train_images=torch.flatten(x_train,start_dim=1)\n",
    "x_train_out2=net2.forward_for_layer(2,train_images)\n",
    "train_true2,train_tot2=lin2.predict(x_train_out2,y_train)\n",
    "print('True: ', train_true2, 'Total: ', train_tot2, 'Error= ', 1-train_true2/train_tot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52ded3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  7949 Total:  10000 Error=  0.20509999999999995\n"
     ]
    }
   ],
   "source": [
    "x_test_out2=net2.forward_for_layer(2,test_images)\n",
    "test_true2,test_tot2=lin2.predict(x_test_out2,y_test)\n",
    "print('True: ', test_true2, 'Total: ', test_tot2, 'Error= ', 1-test_true2/test_tot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe1a70",
   "metadata": {},
   "source": [
    "### Hyperparameter setting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30b6cf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FFLayer(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=600, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "), FFLayer(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")]\n",
      "Training layer:  1\n",
      "Epoch: 20 Running loss: 0.866596\n",
      "Epoch: 40 Running loss: 0.729178\n",
      "Epoch: 60 Running loss: 0.726352\n",
      "Epoch: 80 Running loss: 0.723812\n",
      "Epoch: 100 Running loss: 0.721892\n",
      "Epoch: 120 Running loss: 0.719372\n",
      "Epoch: 140 Running loss: 0.716927\n",
      "Epoch: 160 Running loss: 0.712716\n",
      "Epoch: 180 Running loss: 0.708165\n",
      "Epoch: 200 Running loss: 0.701409\n",
      "Epoch: 220 Running loss: 0.690713\n",
      "Epoch: 240 Running loss: 0.678835\n",
      "Epoch: 260 Running loss: 0.669115\n",
      "Epoch: 280 Running loss: 0.657919\n",
      "Epoch: 300 Running loss: 0.646604\n",
      "Epoch: 320 Running loss: 0.632589\n",
      "Epoch: 340 Running loss: 0.620640\n",
      "Epoch: 360 Running loss: 0.603008\n",
      "Epoch: 380 Running loss: 0.590280\n",
      "Epoch: 400 Running loss: 0.575999\n",
      "Epoch: 420 Running loss: 0.567671\n",
      "Epoch: 440 Running loss: 0.560697\n",
      "Epoch: 460 Running loss: 0.554756\n",
      "Epoch: 480 Running loss: 0.545596\n",
      "Epoch: 500 Running loss: 0.540202\n",
      "Epoch: 520 Running loss: 0.531659\n",
      "Epoch: 540 Running loss: 0.526954\n",
      "Epoch: 560 Running loss: 0.522722\n",
      "Epoch: 580 Running loss: 0.518042\n",
      "Epoch: 600 Running loss: 0.514682\n",
      "Epoch: 620 Running loss: 0.506003\n",
      "Epoch: 640 Running loss: 0.500507\n",
      "Epoch: 660 Running loss: 0.491245\n",
      "Epoch: 680 Running loss: 0.482561\n",
      "Epoch: 700 Running loss: 0.483757\n",
      "Epoch: 720 Running loss: 0.480253\n",
      "Epoch: 740 Running loss: 0.470931\n",
      "Epoch: 760 Running loss: 0.470466\n",
      "Epoch: 780 Running loss: 0.465439\n",
      "Epoch: 800 Running loss: 0.463144\n",
      "Epoch: 820 Running loss: 0.457602\n",
      "Epoch: 840 Running loss: 0.452897\n",
      "Epoch: 860 Running loss: 0.450003\n",
      "Epoch: 880 Running loss: 0.445449\n",
      "Epoch: 900 Running loss: 0.443612\n",
      "Training layer:  2\n",
      "Epoch: 20 Running loss: 0.761166\n",
      "Epoch: 40 Running loss: 0.709615\n",
      "Epoch: 60 Running loss: 0.696006\n",
      "Epoch: 80 Running loss: 0.690449\n",
      "Epoch: 100 Running loss: 0.683483\n",
      "Epoch: 120 Running loss: 0.678958\n",
      "Epoch: 140 Running loss: 0.674080\n",
      "Epoch: 160 Running loss: 0.668379\n",
      "Epoch: 180 Running loss: 0.662354\n",
      "Epoch: 200 Running loss: 0.659785\n",
      "Epoch: 220 Running loss: 0.653240\n",
      "Epoch: 240 Running loss: 0.649566\n",
      "Epoch: 260 Running loss: 0.642366\n",
      "Epoch: 280 Running loss: 0.641615\n",
      "Epoch: 300 Running loss: 0.635808\n",
      "Epoch: 320 Running loss: 0.631315\n",
      "Epoch: 340 Running loss: 0.628022\n",
      "Epoch: 360 Running loss: 0.625223\n",
      "Epoch: 380 Running loss: 0.621828\n",
      "Epoch: 400 Running loss: 0.621925\n",
      "Epoch: 420 Running loss: 0.620109\n",
      "Epoch: 440 Running loss: 0.615499\n",
      "Epoch: 460 Running loss: 0.611673\n",
      "Epoch: 480 Running loss: 0.608922\n",
      "Epoch: 500 Running loss: 0.608681\n",
      "Epoch: 520 Running loss: 0.605440\n",
      "Epoch: 540 Running loss: 0.604494\n",
      "Epoch: 560 Running loss: 0.601813\n",
      "Epoch: 580 Running loss: 0.597980\n",
      "Epoch: 600 Running loss: 0.598959\n",
      "Epoch: 620 Running loss: 0.595222\n",
      "Epoch: 640 Running loss: 0.593477\n",
      "Epoch: 660 Running loss: 0.592706\n",
      "Epoch: 680 Running loss: 0.590964\n",
      "Epoch: 700 Running loss: 0.588438\n",
      "Epoch: 720 Running loss: 0.585391\n",
      "Epoch: 740 Running loss: 0.586533\n",
      "Epoch: 760 Running loss: 0.583959\n",
      "Epoch: 780 Running loss: 0.582637\n",
      "Epoch: 800 Running loss: 0.582397\n",
      "Epoch: 820 Running loss: 0.580199\n",
      "Epoch: 840 Running loss: 0.579914\n",
      "Epoch: 860 Running loss: 0.577928\n",
      "Epoch: 880 Running loss: 0.576693\n",
      "Epoch: 900 Running loss: 0.575122\n"
     ]
    }
   ],
   "source": [
    "net3=FFNet(epsilon=1e-2,dims=[784,600,500],n_mask=5, device=device,dtype=torch.float32, threshold_list=[3, 2], lr=0.01)\n",
    "net3.train(900, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c72be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Running loss: 1.287718\n",
      "Epoch: 10 Running loss: 1.174330\n",
      "Epoch: 15 Running loss: 0.955891\n",
      "Epoch: 20 Running loss: 0.793940\n",
      "Epoch: 25 Running loss: 0.685191\n",
      "Epoch: 30 Running loss: 0.614353\n",
      "Epoch: 35 Running loss: 0.558119\n",
      "Epoch: 40 Running loss: 0.519524\n",
      "Epoch: 45 Running loss: 0.492863\n",
      "Epoch: 50 Running loss: 0.477686\n",
      "Epoch: 55 Running loss: 0.462478\n",
      "Epoch: 60 Running loss: 0.452165\n",
      "Epoch: 65 Running loss: 0.446103\n",
      "Epoch: 70 Running loss: 0.439405\n",
      "Epoch: 75 Running loss: 0.434220\n",
      "Epoch: 80 Running loss: 0.429872\n",
      "Epoch: 85 Running loss: 0.426118\n",
      "Epoch: 90 Running loss: 0.422612\n",
      "Epoch: 95 Running loss: 0.419438\n",
      "Epoch: 100 Running loss: 0.416440\n",
      "Epoch: 105 Running loss: 0.413651\n",
      "Epoch: 110 Running loss: 0.411015\n",
      "Epoch: 115 Running loss: 0.408521\n",
      "Epoch: 120 Running loss: 0.406144\n",
      "Epoch: 125 Running loss: 0.403878\n",
      "Epoch: 130 Running loss: 0.401710\n",
      "Epoch: 135 Running loss: 0.399633\n",
      "Epoch: 140 Running loss: 0.397638\n",
      "Epoch: 145 Running loss: 0.395722\n",
      "Epoch: 150 Running loss: 0.393876\n",
      "Epoch: 155 Running loss: 0.392098\n",
      "Epoch: 160 Running loss: 0.390381\n",
      "Epoch: 165 Running loss: 0.388723\n",
      "Epoch: 170 Running loss: 0.387120\n",
      "Epoch: 175 Running loss: 0.385567\n",
      "Epoch: 180 Running loss: 0.384063\n",
      "Epoch: 185 Running loss: 0.382605\n",
      "Epoch: 190 Running loss: 0.381189\n",
      "Epoch: 195 Running loss: 0.379815\n",
      "Epoch: 200 Running loss: 0.378478\n"
     ]
    }
   ],
   "source": [
    "lin3=Linear_classifier(epsilon=1e-2, in_dim=500, num_classes=10, lr=0.02, device=device,dtype=torch.float32)\n",
    "x_out3=net3.forward_for_layer(2,images)\n",
    "lin3.train(x_out3,y_train,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed25c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  43735 Total:  50000 Error=  0.12529999999999997\n"
     ]
    }
   ],
   "source": [
    "x_train_out3=net3.forward_for_layer(2,train_images)\n",
    "train_true3,train_tot3=lin3.predict(x_train_out3,y_train)\n",
    "print('True: ', train_true3, 'Total: ', train_tot3, 'Error= ', 1-train_true3/train_tot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cd97f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  8744 Total:  10000 Error=  0.12560000000000004\n"
     ]
    }
   ],
   "source": [
    "x_test_out3=net3.forward_for_layer(2,test_images)\n",
    "test_true3,test_tot3=lin3.predict(x_test_out3,y_test)\n",
    "print('True: ', test_true3, 'Total: ', test_tot3, 'Error= ', 1-test_true3/test_tot3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79182fcf",
   "metadata": {},
   "source": [
    "### Result report 2 <br>\n",
    "It appears that just by increasing the training epochs on the last linear classifier, we can achieve a 80% accuracy on both the train set and the test set.\n",
    "\n",
    "Also, by changing th neuron sizes to 600 and 500, we were able to achieve an accuracy of 87.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe3420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
